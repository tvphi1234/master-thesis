import matplotlib.pyplot as plt
import numpy as np
import ast
import os
from pathlib import Path

# Model data extracted from log files
models_data = {
    'Ensemble Average': {
        'train_accuracies': [0.8035117056856187, 0.9222408026755854, 0.9439799331103679, 0.9515050167224081, 0.9498327759197325, 0.955685618729097, 0.959866220735786, 0.9615384615384616, 0.9765886287625417, 0.9690635451505016, 0.9640468227424749, 0.9749163879598661, 0.979933110367893, 0.9790969899665553, 0.9824414715719064, 0.9774247491638797, 0.9849498327759197, 0.979933110367893, 0.9782608695652173, 0.9816053511705686, 0.9774247491638797, 0.9874581939799332, 0.9790969899665553, 0.9740802675585285, 0.984113712374582, 0.9849498327759197, 0.9866220735785953, 0.9816053511705686, 0.9807692307692308, 0.9866220735785953],
        'val_accuracies': [0.8806451612903226, 0.9548387096774194, 0.9548387096774194, 0.9516129032258064, 0.9548387096774194, 0.9709677419354839, 0.9483870967741936, 0.967741935483871, 0.967741935483871, 0.9741935483870968, 0.9709677419354839, 0.9774193548387096, 0.9774193548387096, 0.9838709677419355, 0.967741935483871, 0.9612903225806452, 0.9774193548387096, 0.9838709677419355, 0.9870967741935484, 0.9806451612903225, 0.9774193548387096, 0.9806451612903225, 0.9870967741935484, 0.9870967741935484, 0.9774193548387096, 0.964516129032258, 0.9612903225806452, 0.9838709677419355, 0.9838709677419355, 0.9741935483870968],
        'train_losses': [0.4585477044185003, 0.22868402709563573, 0.16425538212060928, 0.1402295982092619, 0.1280944096793731, 0.11179573933283488, 0.10366703453163306, 0.09182264750202497, 0.07556959497431914, 0.08623973667000731, 0.08319691037759185, 0.06904129277604322, 0.06288498137767116, 0.0729084722759823, 0.059480924389014644, 0.06665069166726122, 0.046726609726125995, 0.0511912666944166, 0.0688812068880846, 0.04858658853607873, 0.05708435682890316, 0.04575364580222716, 0.04954405019370218, 0.05762901954973738, 0.04615614240212987, 0.04347903279587626, 0.0439262291106085, 0.046579944390493136, 0.054846388009221606, 0.04295581843781596],
        'val_losses': [0.3439787067472935, 0.24737528190016747, 0.1722581811249256, 0.15454717688262462, 0.14284032806754113, 0.11260725101456046, 0.13997501647099853, 0.09145685569383204, 0.10103747092653066, 0.07824482021387666, 0.07262286967597902, 0.07035728468326852, 0.05919006996264216, 0.054700101474008986, 0.06731639666249975, 0.07629642143729143, 0.049896666230779374, 0.055918224243214354, 0.046748100775766945, 0.043640576052894176, 0.04188358592530221, 0.042856654167644594, 0.028278951348443115, 0.03212840363609075, 0.04871835446119803, 0.08612207686310284, 0.08059430841603898, 0.041337226851419474, 0.034562259614085634, 0.05452431296907889],
        'best_accuracy': 0.9871,
        'epochs': 30
    },
    'Ensemble Feature Fusion': {
        'train_accuracies': [0.7391304347826088, 0.9280936454849499, 0.9389632107023411, 0.9498327759197325, 0.9515050167224081, 0.9698996655518394, 0.955685618729097, 0.9749163879598661, 0.9623745819397993, 0.9765886287625417, 0.9665551839464882, 0.9623745819397993, 0.9732441471571905, 0.9765886287625417, 0.9816053511705686, 0.9774247491638797, 0.984113712374582, 0.9757525083612041, 0.979933110367893, 0.9824414715719064, 0.9774247491638797, 0.9832775919732442, 0.9849498327759197, 0.9866220735785953, 0.9933110367892977, 0.9933110367892977, 0.9874581939799332, 0.9899665551839465, 0.9832775919732442, 0.9849498327759197],
        'val_accuracies': [0.9129032258064517, 0.9451612903225807, 0.9451612903225807, 0.9612903225806452, 0.9774193548387096, 0.9774193548387096, 0.9741935483870968, 0.9612903225806452, 0.9709677419354839, 0.9806451612903225, 0.9709677419354839, 0.9806451612903225, 0.9903225806451613, 0.9806451612903225, 0.9870967741935484, 0.9838709677419355, 0.9838709677419355, 0.9935483870967743, 0.9741935483870968, 0.9838709677419355, 0.9741935483870968, 0.9838709677419355, 0.9774193548387096, 0.9806451612903225, 0.9870967741935484, 0.9838709677419355, 0.9838709677419355, 0.9709677419354839, 0.9806451612903225, 0.9806451612903225],
        'train_losses': [0.4917216090361277, 0.19458309543629487, 0.16126092274983725, 0.15098528228700162, 0.11513759183386961, 0.0804990672133863, 0.10167876614878575, 0.08952693810686468, 0.10465965141852697, 0.07459678361813227, 0.0841305088189741, 0.11211977800664802, 0.0630025573959574, 0.05500071816767255, 0.05292040106374771, 0.06150232660351321, 0.054309066138230264, 0.07280418939966088, 0.05454841179617991, 0.048533294037915765, 0.06076300552890947, 0.04930801064940169, 0.043954547716615104, 0.035912970162268416, 0.02874576789016525, 0.02140897842706181, 0.033596121238078924, 0.025509660103125498, 0.05397660918941256, 0.03916271713407089],
        'val_losses': [0.36238907650113106, 0.19450973346829414, 0.15850101504474878, 0.13691369108855725, 0.09658798193559051, 0.07395265361992642, 0.07715204756823368, 0.07753861970850266, 0.07766160377068446, 0.05083273583150003, 0.07156035567168147, 0.06322589145856909, 0.04087743159325328, 0.05264968295123253, 0.059104639519136984, 0.056374638402485286, 0.06847989806701663, 0.050736389341182075, 0.07067532661021687, 0.058199191217136105, 0.07400245414464734, 0.05762637511943467, 0.04589752728352323, 0.055624230602552414, 0.0478724086224247, 0.062432777932554015, 0.04853447262867121, 0.08170481066626963, 0.06747495937888744, 0.05660514308328857],
        'best_accuracy': 0.9935,
        'epochs': 30
    },
    'ResNet50': {
        'train_accuracies': [0.6989966555183946, 0.782608695652174, 0.8051839464882943, 0.8168896321070234, 0.8478260869565217, 0.8595317725752508, 0.8503344481605352, 0.8879598662207357, 0.8762541806020067, 0.8971571906354515, 0.8929765886287625, 0.9096989966555183, 0.9055183946488294, 0.9214046822742475, 0.9205685618729097, 0.9163879598662207, 0.9096989966555183, 0.9331103678929766, 0.9331103678929766, 0.9331103678929766, 0.9297658862876255, 0.9481605351170569, 0.9364548494983278, 0.9448160535117057, 0.9489966555183946, 0.9464882943143813, 0.9464882943143813, 0.947324414715719, 0.9481605351170569, 0.9515050167224081],
        'val_accuracies': [0.6806451612903226, 0.6806451612903226, 0.7709677419354839, 0.8032258064516129, 0.6451612903225806, 0.8548387096774194, 0.8806451612903226, 0.6967741935483871, 0.896774193548387, 0.8774193548387097, 0.8838709677419355, 0.8709677419354839, 0.7290322580645161, 0.7774193548387097, 0.8870967741935484, 0.8, 0.7548387096774194, 0.6419354838709678, 0.7709677419354839, 0.8193548387096774, 0.9032258064516129, 0.832258064516129, 0.7483870967741936, 0.932258064516129, 0.8709677419354839, 0.9032258064516129, 0.9096774193548387, 0.9064516129032258, 0.9129032258064517, 0.9387096774193548],
        'train_losses': [0.5721552826856312, 0.4753843389059368, 0.43143372472963837, 0.39900413155555725, 0.3561087501676459, 0.33063518530444097, 0.31389344601254715, 0.2605112304812984, 0.27612246023981196, 0.24936337925885854, 0.23535617323298202, 0.2216168673414933, 0.21753243749078952, 0.19053921221118225, 0.1755118291628988, 0.2181776742401876, 0.21005221142580635, 0.17037502597821386, 0.1647540393628572, 0.17325558297728239, 0.1863860127172972, 0.1506054752359265, 0.1561240687182075, 0.14890595447075994, 0.14120693857732572, 0.13359139565574496, 0.13826058314819084, 0.14130793433440358, 0.12631916450826744, 0.12570607270065107],
        'val_losses': [0.719422048330307, 1.1865455240011216, 0.49970114082098005, 0.4058101296424866, 0.7428040415048599, 0.3203598201274872, 0.3296771377325058, 0.6517889574170113, 0.2634502276778221, 0.2528109811246395, 0.269347158074379, 0.3291592299938202, 0.6129664219915867, 0.6459969794377685, 0.2358860470354557, 0.6111062349751591, 0.5550920315086841, 1.1775650724768638, 0.6921590283513069, 0.5226524233818054, 0.22080908715724945, 0.4135210461914539, 0.7940789112588391, 0.18147025108337403, 0.33794817626476287, 0.22723277434706687, 0.2717077486217022, 0.2426642395555973, 0.30191665741149337, 0.1915986455976963],
        'best_accuracy': 0.9387,
        'epochs': 30
    },
    'Xception': {
        'train_accuracies': [0.681438127090301, 0.7132107023411371, 0.7608695652173914, 0.7851170568561873, 0.8285953177257525, 0.8352842809364549, 0.8745819397993311, 0.8603678929765887, 0.8804347826086957, 0.8846153846153846, 0.903010033444816, 0.8879598662207357, 0.9021739130434783, 0.907190635451505, 0.9138795986622074, 0.9347826086956522, 0.9297658862876255, 0.939799331103679],
        'val_accuracies': [0.6806451612903226, 0.7322580645161291, 0.6838709677419355, 0.8774193548387097, 0.8548387096774194, 0.7419354838709677, 0.9, 0.8387096774193549, 0.8903225806451613, 0.8774193548387097, 0.9387096774193548, 0.832258064516129, 0.9161290322580645, 0.9290322580645162, 0.9096774193548387, 0.9258064516129032, 0.9354838709677419, 0.9354838709677419],
        'train_losses': [0.5992494703907716, 0.547285501894198, 0.4637529646095477, 0.41434469583787414, 0.34975428134202957, 0.374850337050463, 0.30475072425447014, 0.33022935374786977, 0.28829911841373695, 0.2796628286964015, 0.2660140706912467, 0.25627109114276736, 0.224867547225011, 0.22948957156193883, 0.21435935775700368, 0.19492438612015625, 0.17677469316281771, 0.1608442660225065],
        'val_losses': [0.6665325582027435, 0.5888519167900086, 0.5276193576864898, 0.29580137953162194, 0.334598845615983, 0.4443662853911519, 0.2619044613093138, 0.3657723717391491, 0.23219896648079158, 0.28251856602728365, 0.18575117867439986, 0.3645381538197398, 0.22161496579647064, 0.19193457001820208, 0.24970609173178673, 0.1911541407927871, 0.16445269542746246, 0.15860113906674086],
        'best_accuracy': 0.9355,
        'epochs': 18  # Early stopping
    }
}


def plot_training_comparison():
    """
    Create comprehensive training comparison plots
    """
    plt.style.use('default')

    # Create figure with subplots
    fig = plt.figure(figsize=(20, 12))

    # Define colors for each model
    colors = {
        'Ensemble Average': '#1f77b4',
        'Ensemble Feature Fusion': '#ff7f0e',
        'ResNet50': '#2ca02c',
        'Xception': '#d62728'
    }

    # 1. Training Accuracy Comparison
    ax1 = plt.subplot(2, 3, 1)
    for model_name, data in models_data.items():
        epochs = range(1, len(data['train_accuracies']) + 1)
        plt.plot(epochs, data['train_accuracies'],
                 color=colors[model_name], linewidth=2.5,
                 label=f"{model_name} (Max: {max(data['train_accuracies']):.3f})")

    plt.title('Training Accuracy Comparison', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0.65, 1.0)

    # 2. Validation Accuracy Comparison
    ax2 = plt.subplot(2, 3, 2)
    for model_name, data in models_data.items():
        epochs = range(1, len(data['val_accuracies']) + 1)
        plt.plot(epochs, data['val_accuracies'],
                 color=colors[model_name], linewidth=2.5,
                 label=f"{model_name} (Best: {data['best_accuracy']:.3f})")

    plt.title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0.65, 1.0)

    # 3. Training Loss Comparison
    ax3 = plt.subplot(2, 3, 4)
    for model_name, data in models_data.items():
        epochs = range(1, len(data['train_losses']) + 1)
        plt.plot(epochs, data['train_losses'],
                 color=colors[model_name], linewidth=2.5,
                 label=f"{model_name} (Final: {data['train_losses'][-1]:.3f})")

    plt.title('Training Loss Comparison', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')

    # 4. Validation Loss Comparison
    ax4 = plt.subplot(2, 3, 5)
    for model_name, data in models_data.items():
        epochs = range(1, len(data['val_losses']) + 1)
        plt.plot(epochs, data['val_losses'],
                 color=colors[model_name], linewidth=2.5,
                 label=f"{model_name} (Final: {data['val_losses'][-1]:.3f})")

    plt.title('Validation Loss Comparison', fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')

    # 5. Best Validation Accuracy Bar Chart
    ax5 = plt.subplot(2, 3, 3)
    model_names = list(models_data.keys())
    best_accuracies = [models_data[name]['best_accuracy']
                       for name in model_names]

    bars = plt.bar(model_names, best_accuracies,
                   color=[colors[name] for name in model_names], alpha=0.7)

    # Add value labels on bars
    for bar, acc in zip(bars, best_accuracies):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                 f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.title('Best Validation Accuracy Comparison',
              fontsize=14, fontweight='bold')
    plt.ylabel('Accuracy')
    plt.ylim(0.92, 1.0)
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3, axis='y')

    # 6. Learning Curves (Training vs Validation for each model)
    ax6 = plt.subplot(2, 3, 6)

    for i, (model_name, data) in enumerate(models_data.items()):
        epochs = range(1, len(data['train_accuracies']) + 1)

        # Plot training and validation curves
        plt.plot(epochs, data['train_accuracies'],
                 color=colors[model_name], linestyle='-', alpha=0.7,
                 label=f'{model_name} (Train)')
        plt.plot(epochs, data['val_accuracies'],
                 color=colors[model_name], linestyle='--', linewidth=2,
                 label=f'{model_name} (Val)')

    plt.title('Learning Curves: Train vs Validation',
              fontsize=14, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.ylim(0.65, 1.0)

    plt.tight_layout()

    # Save the plot
    output_path = Path('models') / 'training_comparison.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"Training comparison plot saved to: {output_path}")

    plt.show()


def print_model_summary():
    """
    Print a comprehensive summary of all models
    """
    print("=" * 80)
    print("TRAINING RESULTS SUMMARY")
    print("=" * 80)

    for model_name, data in models_data.items():
        print(f"\nğŸ“Š {model_name}")
        print("-" * 50)
        print(
            f"Best Validation Accuracy: {data['best_accuracy']:.4f} ({data['best_accuracy']*100:.2f}%)")
        print(
            f"Final Training Accuracy:  {data['train_accuracies'][-1]:.4f} ({data['train_accuracies'][-1]*100:.2f}%)")
        print(
            f"Final Validation Accuracy: {data['val_accuracies'][-1]:.4f} ({data['val_accuracies'][-1]*100:.2f}%)")
        print(f"Final Training Loss:      {data['train_losses'][-1]:.4f}")
        print(f"Final Validation Loss:    {data['val_losses'][-1]:.4f}")
        print(f"Epochs Completed:         {data['epochs']}")

        # Calculate overfitting indicator
        train_val_gap = data['train_accuracies'][-1] - \
            data['val_accuracies'][-1]
        print(
            f"Train-Val Gap:            {train_val_gap:.4f} ({'âš ï¸ Overfitting' if train_val_gap > 0.05 else 'âœ… Good'})")

    # Ranking
    print(f"\nğŸ† RANKING BY BEST VALIDATION ACCURACY:")
    print("-" * 50)
    sorted_models = sorted(models_data.items(),
                           key=lambda x: x[1]['best_accuracy'], reverse=True)

    for i, (model_name, data) in enumerate(sorted_models, 1):
        medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
        print(
            f"{medal} {model_name}: {data['best_accuracy']:.4f} ({data['best_accuracy']*100:.2f}%)")


if __name__ == "__main__":
    print("ğŸ” Analyzing training logs and creating visualizations...")

    # Print summary
    print_model_summary()

    # Create plots
    print(f"\nğŸ“ˆ Creating comparison plots...")
    plot_training_comparison()

    print(f"\nâœ… Analysis complete!")
    print(f"ğŸ“ Check the 'models/training_comparison.png' file for detailed visualizations.")
